{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1dc04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2f67d",
   "metadata": {},
   "source": [
    "# Importing CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68c09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BTC = pd.read_csv(\"BTC_Historical_11-03.csv\", index_col=0)\n",
    "df_DOGE = pd.read_csv(\"DOGE_Historical_11-03.csv\", index_col=0)\n",
    "df_XRP = pd.read_csv(\"XRP_Historical_11-03.csv\", index_col=0)\n",
    "df_ETH = pd.read_csv(\"ETH_Historical_11-03.csv\", index_col=0)\n",
    "df_UNI = pd.read_csv(\"UNI_Historical_11-03.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06ee36",
   "metadata": {},
   "source": [
    "# Using feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57775b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f304f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 271535.7147975525\n"
     ]
    }
   ],
   "source": [
    "df_BTC['Difference between opening and closing'] = df_BTC['Opening Price (USD)'] - df_BTC['Closing Price (USD)']\n",
    "\n",
    "# Define features and target variable\n",
    "# Assuming you want to predict the future highest price\n",
    "X = df_BTC.drop(columns=['Highest Price (USD)'])\n",
    "y = df_BTC['Highest Price (USD)']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534b2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 265707.5387310729\n"
     ]
    }
   ],
   "source": [
    "X = df_BTC.drop(columns=['Highest Price (USD)'])\n",
    "y = df_BTC['Highest Price (USD)']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline for preprocessing and modeling\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the testing set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce70369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolasstahl/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/nikolasstahl/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.20122D+00    |proj g|=  3.47666D-02\n",
      "\n",
      "At iterate    5    f=  8.19952D+00    |proj g|=  3.89565D-03\n",
      "\n",
      "At iterate   10    f=  8.19946D+00    |proj g|=  2.42206D-03\n",
      "\n",
      "At iterate   15    f=  8.19944D+00    |proj g|=  5.82916D-04\n",
      "\n",
      "At iterate   20    f=  8.19923D+00    |proj g|=  8.00249D-03\n",
      "\n",
      "At iterate   25    f=  8.17390D+00    |proj g|=  1.16124D-01\n",
      "\n",
      "At iterate   30    f=  8.12471D+00    |proj g|=  1.15415D-03\n",
      "\n",
      "At iterate   35    f=  8.12451D+00    |proj g|=  1.12578D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     39     43      1     0     0   3.306D-05   8.124D+00\n",
      "  F =   8.1244828610002315     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Predicted Highest Price for 2024-03-12 00:00:00: 26510.65605440646\n",
      "Predicted Highest Price for 2024-03-13 00:00:00: 26553.716013269735\n",
      "Predicted Highest Price for 2024-03-14 00:00:00: 26528.9878483047\n",
      "Predicted Highest Price for 2024-03-15 00:00:00: 26526.56229061564\n",
      "Predicted Highest Price for 2024-03-16 00:00:00: 26459.952135088384\n",
      "Predicted Highest Price for 2024-03-17 00:00:00: 26047.03128398921\n",
      "Predicted Highest Price for 2024-03-18 00:00:00: 25992.038503407966\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df_BTC) * 0.8)\n",
    "train_data, test_data = df_BTC.iloc[:train_size], df_BTC.iloc[train_size:]\n",
    "\n",
    "# Define the SARIMA model\n",
    "order = (1, 1, 1)  # ARIMA order\n",
    "seasonal_order = (1, 1, 1, 12)  # SARIMA seasonal order\n",
    "sarima_model = SARIMAX(train_data['Highest Price (USD)'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)\n",
    "\n",
    "# Fit the SARIMA model\n",
    "sarima_result = sarima_model.fit()\n",
    "\n",
    "# Forecast future values\n",
    "forecast_periods = 7  # Forecasting for the next 7 days\n",
    "forecast = sarima_result.forecast(steps=forecast_periods)\n",
    "\n",
    "# Create a range of future dates for the forecasted periods\n",
    "future_dates = pd.date_range(start=df_BTC.index[-1], periods=forecast_periods + 1, freq='D')[1:]  # Start from the day after the last date in the dataset\n",
    "\n",
    "# Print the forecasted values for each future date\n",
    "for date, prediction in zip(future_dates, forecast):\n",
    "    print(f\"Predicted Highest Price for {date}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a60ec3",
   "metadata": {},
   "source": [
    "# Time Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3162315",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x is required to have ndim 1 but has ndim 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstattools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adfuller\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming your time series data is stored in a variable called 'ts_data'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m adfuller(df_BTC)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADF Statistic:\u001b[39m\u001b[38;5;124m'\u001b[39m, result[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp-value:\u001b[39m\u001b[38;5;124m'\u001b[39m, result[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:261\u001b[0m, in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madfuller\u001b[39m(\n\u001b[1;32m    167\u001b[0m     x,\n\u001b[1;32m    168\u001b[0m     maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     regresults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    173\u001b[0m ):\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    Augmented Dickey-Fuller unit root test.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m        http://ideas.repec.org/p/qed/wpaper/1227.html\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     x \u001b[38;5;241m=\u001b[39m array_like(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m     maxlag \u001b[38;5;241m=\u001b[39m int_like(maxlag, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    263\u001b[0m     regression \u001b[38;5;241m=\u001b[39m string_like(\n\u001b[1;32m    264\u001b[0m         regression, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m, options\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/statsmodels/tools/validation/validation.py:155\u001b[0m, in \u001b[0;36marray_like\u001b[0;34m(obj, name, dtype, ndim, maxdim, shape, order, contiguous, optional, writeable)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m ndim:\n\u001b[1;32m    154\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is required to have ndim \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m but has ndim \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, ndim, arr\u001b[38;5;241m.\u001b[39mndim))\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m actual, req \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape, shape):\n",
      "\u001b[0;31mValueError\u001b[0m: x is required to have ndim 1 but has ndim 2"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Assuming your time series data is stored in a variable called 'ts_data'\n",
    "result = adfuller(df_BTC)\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "print('Critical Values:', result[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b523db93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolasstahl/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/nikolasstahl/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.20204D+00    |proj g|=  4.95948D-02\n",
      "\n",
      "At iterate    5    f=  8.19963D+00    |proj g|=  3.48393D-03\n",
      "\n",
      "At iterate   10    f=  8.19868D+00    |proj g|=  1.12245D-02\n",
      "\n",
      "At iterate   15    f=  8.19833D+00    |proj g|=  7.90586D-04\n",
      "\n",
      "At iterate   20    f=  8.19830D+00    |proj g|=  1.55466D-03\n",
      "\n",
      "At iterate   25    f=  8.19665D+00    |proj g|=  8.21315D-03\n",
      "\n",
      "At iterate   30    f=  8.18945D+00    |proj g|=  5.13126D-02\n",
      "\n",
      "At iterate   35    f=  8.13130D+00    |proj g|=  4.33306D-02\n",
      "\n",
      "At iterate   40    f=  8.12533D+00    |proj g|=  1.32740D-02\n",
      "\n",
      "At iterate   45    f=  8.12157D+00    |proj g|=  7.24784D-03\n",
      "\n",
      "At iterate   50    f=  8.12146D+00    |proj g|=  2.49267D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     50     62      1     0     0   2.493D-05   8.121D+00\n",
      "  F =   8.1214606353080558     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikolasstahl/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 17977.03935295564\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(df_BTC) * 0.8)\n",
    "train_data, test_data = df_BTC.iloc[:train_size], df_BTC.iloc[train_size:]\n",
    "\n",
    "# Define the SARIMA model\n",
    "# Adjust the order and seasonal_order parameters based on your data and domain knowledge\n",
    "order = (2, 1, 1)  # ARIMA order\n",
    "seasonal_order = (1, 1, 1, 12)  # SARIMA seasonal order\n",
    "model = SARIMAX(train_data['Highest Price (USD)'], order=order, seasonal_order=seasonal_order, enforce_stationarity=False)\n",
    "\n",
    "sarima_model = model.fit()\n",
    "\n",
    "# Predictions\n",
    "start_index = len(train_data)\n",
    "end_index = start_index + len(test_data) - 1\n",
    "predictions = sarima_model.predict(start=start_index, end=end_index, dynamic=False)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(test_data['Highest Price (USD)'], predictions)\n",
    "rmse = sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# You can now use the trained SARIMA model to make predictions for future time periods\n",
    "# For example, to predict the next 7 days:\n",
    "# future_forecast = sarima_model.forecast(steps=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd258c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-08-25    26464.953783\n",
       "2023-08-26    26496.188539\n",
       "2023-08-27    26467.920784\n",
       "2023-08-28    26472.421535\n",
       "2023-08-29    26405.706561\n",
       "2023-08-30    26016.883636\n",
       "2023-08-31    25971.673896\n",
       "Freq: D, Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_forecast_TS = sarima_model.forecast(steps=7)\n",
    "future_forecast_TS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
